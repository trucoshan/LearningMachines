# LearningMachines

A collaborative, no-frameworks (beyond NumPy) machine learning repo built from first principles.  
We implement core algorithms line-by-line to understand the math, not just call `.fit()`.

> Status: ✅ Logistic Regression (from scratch) · ⏭️ Next: Support Vector Machines

---

## Table of Contents
- [Goals](#goals)
- [What’s Inside](#whats-inside)
- [ToDo](#ToDo)
- [Roadmap](#roadmap)

---

## Goals

- Demystify ML by **implementing algorithms from scratch**.
- Build a **friendly collaboration space** for anyone and everyone.
- Keep code **minimal, readable, and well-documented**.
- Add **tests and examples** as we go.

---

## What’s Inside

- **Linear Regression (from scratch)**
  - Gradient Descent optimization
  - Stochastic Gradient Descent optimization
  - Arbitrary feature dimensions
  - Minimal dependencies

- **Logistic Regression (from scratch)**
  - Gradient Descent optimization
  - Minimal dependencies
  - Logistic hypothesis (sigmoid) 
  - Cross-entropy cost 
  - Gradient Descent 
  - Weight initialization 
  - Feature standardization 
  - Proper train–validation split 
  - Convergence checks 
  - Forward + backward pass 
  - Evaluation pipeline (MSE/RMSE) 
  - End-to-end NumPy workflow


## ToDo

> ToDo : Add **docstrings** and **comments** in model.py [Linear Regression and Logistic Regression from scratch]

---

## Roadmap

- [x] Linear Regression (GD & SGD)
- [x] Logistic Regression (Binary)
- [ ] Support Vector Machines
- [x] Metrics: MSE, MAE, Accuracy, Precision/Recall
- [x] Train/Val split utilities
- [ ] Visualization helpers
- [ ] Unit tests (pytest)
- [ ] Additional models: KNN, Decision Trees
